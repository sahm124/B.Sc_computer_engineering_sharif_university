{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "### guide :\n",
    "### this file load model and dataset and apply fgsm attack on it and saves the results\n",
    "### if want to save the adv_images check for commented line in evaluate_functon\n",
    "### if model should load in specific way check for load model which highlighted by a comment\n",
    "### dataset format should be like VGGFace2\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#  Parameters\n",
    "train_dir = 'O:/project/dataset/train'\n",
    "val_dir = 'O:/project/dataset/val'\n",
    "test_dir = 'O:/project/dataset/test'\n",
    "base_save_dir = 'E:/Downloads/sayed_hasan_mofi/dataset/fsgm_mobile_sgd_v4fined_e100'\n",
    "model_path = 'E:/Downloads/sayed_hasan_mofi/epochs/mobile_sgd_v4_fined/model_epoch_100.keras'\n",
    "img_height = 160\n",
    "img_width = 160 \n",
    "batch_size = 128\n",
    "epsilon_values = [0.05, 0.1, 0.15, 0.2]\n",
    "\n",
    "\n",
    "#################################################################################################################\n",
    "### main code\n",
    "os.makedirs(base_save_dir, exist_ok=True)\n",
    "\n",
    "def load_dataset(data_dir):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        label_mode='int',\n",
    "        shuffle=False \n",
    "    )\n",
    "    \n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "\n",
    "    file_paths.sort()\n",
    "    return dataset, file_paths\n",
    "\n",
    "train_dataset, train_file_paths = load_dataset(train_dir)\n",
    "val_dataset, val_file_paths = load_dataset(val_dir)\n",
    "test_dataset, test_file_paths = load_dataset(test_dir)\n",
    "\n",
    "class_names = test_dataset.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "def preprocess_label(label):\n",
    "    return tf.one_hot(label, num_classes)\n",
    "\n",
    "def preprocess_data(x, y):\n",
    "    x = x * (1. / 255)\n",
    "    y = preprocess_label(y)\n",
    "    return x, y\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_data)\n",
    "val_dataset = val_dataset.map(preprocess_data)\n",
    "test_dataset = test_dataset.map(preprocess_data)\n",
    "\n",
    "def fgsm_attack(model, x, y, epsilon):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        prediction = model(x)\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y, prediction)\n",
    "\n",
    "    gradient = tape.gradient(loss, x)\n",
    "\n",
    "    signed_grad = tf.sign(gradient)\n",
    "\n",
    "    adv_x = x + epsilon * signed_grad\n",
    "\n",
    "    adv_x = tf.clip_by_value(adv_x, 0, 1)\n",
    "\n",
    "    return adv_x\n",
    "\n",
    "\n",
    "def save_adversarial_images(adv_images, image_paths, base_save_dir):\n",
    "    adv_images = (adv_images * 255).numpy().astype(np.uint8)\n",
    "    for i, adv_image in enumerate(adv_images):\n",
    "        img = Image.fromarray(adv_image)\n",
    "        original_filepath = image_paths[i].decode('utf-8') if isinstance(image_paths[i], bytes) else image_paths[i]\n",
    "        relative_path = os.path.relpath(original_filepath, start=os.path.dirname(train_dir))\n",
    "        save_path = os.path.join(base_save_dir, relative_path)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        img.save(save_path)\n",
    "\n",
    "def evaluate_clean_accuracy(model, dataset):\n",
    "    accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    for x_batch, y_batch in dataset:\n",
    "        predictions = model(x_batch)\n",
    "        accuracy.update_state(y_batch, predictions)\n",
    "    return accuracy.result().numpy() * 100\n",
    "\n",
    "def evaluate_and_save(model, dataset, file_paths, epsilon, save_dir):\n",
    "    clean_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "    adv_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    for batch_index, (x_batch, y_batch) in enumerate(dataset):\n",
    "        start_idx = batch_index * batch_size\n",
    "        end_idx = start_idx + x_batch.shape[0]\n",
    "        image_paths = file_paths[start_idx:end_idx]\n",
    "\n",
    "        x_adv_batch = fgsm_attack(model, x_batch, y_batch, epsilon)\n",
    "\n",
    "        clean_predictions = model(x_batch)\n",
    "        clean_accuracy.update_state(y_batch, clean_predictions)\n",
    "\n",
    "        adv_predictions = model(x_adv_batch)\n",
    "        adv_accuracy.update_state(y_batch, adv_predictions)\n",
    "\n",
    "        # save_adversarial_images(x_adv_batch, image_paths, save_dir)\n",
    "\n",
    "    clean_acc = clean_accuracy.result().numpy() * 100\n",
    "    adv_acc = adv_accuracy.result().numpy() * 100\n",
    "    print(f\"Epsilon: {epsilon:.2f} | Clean accuracy: {clean_acc:.2f}% | Adversarial accuracy: {adv_acc:.2f}%\")\n",
    "    \n",
    "    return clean_acc, adv_acc\n",
    "\n",
    "#load model\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "train_clean_accuracy = evaluate_clean_accuracy(model, train_dataset)\n",
    "val_clean_accuracy = evaluate_clean_accuracy(model, val_dataset)\n",
    "test_clean_accuracy = evaluate_clean_accuracy(model, test_dataset)\n",
    "\n",
    "print(f\"Train Clean Accuracy: {train_clean_accuracy:.2f}%\")\n",
    "print(f\"Validation Clean Accuracy: {val_clean_accuracy:.2f}%\")\n",
    "print(f\"Test Clean Accuracy: {test_clean_accuracy:.2f}%\")\n",
    "\n",
    "# Evaluate the model for different epsilon values and save the results\n",
    "clean_accuracies = []\n",
    "adv_accuracies = []\n",
    "\n",
    "for epsilon in epsilon_values:\n",
    "    epsilon_save_dir = os.path.join(base_save_dir, f'epsilon_{epsilon}')\n",
    "    clean_acc, adv_acc = evaluate_and_save(model, test_dataset, val_file_paths, epsilon, epsilon_save_dir)\n",
    "    clean_accuracies.append(clean_acc)\n",
    "    adv_accuracies.append(adv_acc)\n",
    "\n",
    "figure_path = os.path.join(base_save_dir, 'accuracy_vs_epsilon.png')\n",
    "results_txt_path = os.path.join(base_save_dir, 'accuracy_results.txt')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epsilon_values, clean_accuracies, label='Clean Accuracy', marker='o')\n",
    "plt.plot(epsilon_values, adv_accuracies, label='Adversarial Accuracy', marker='o')\n",
    "plt.title('Model Accuracy vs. Epsilon')\n",
    "plt.xlabel('Epsilon')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.savefig(figure_path)\n",
    "plt.show()\n",
    "\n",
    "with open(results_txt_path, 'w') as f:\n",
    "    f.write(f\"Train Clean Accuracy: {train_clean_accuracy:.2f}%\\n\")\n",
    "    f.write(f\"Validation Clean Accuracy: {val_clean_accuracy:.2f}%\\n\")\n",
    "    f.write(f\"Test Clean Accuracy: {test_clean_accuracy:.2f}%\\n\\n\")\n",
    "    \n",
    "    for epsilon, clean_acc, adv_acc in zip(epsilon_values, clean_accuracies, adv_accuracies):\n",
    "        f.write(f\"Epsilon: {epsilon:.2f} | Clean accuracy: {clean_acc:.2f}% | Adversarial accuracy: {adv_acc:.2f}%\\n\")\n",
    "\n",
    "print(f\"Figure saved at {figure_path}\")\n",
    "print(f\"Results saved at {results_txt_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
